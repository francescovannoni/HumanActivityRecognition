\author{Francesco Vannoni}
\documentclass[]{article}
\title{Human Activity Recognition}
\date{}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[margin=0.7in]{geometry}
\usepackage[italian]{babel}

\begin{document}
\begin{figure}
\maketitle
\section{Introduzione}
\textit{"A decision tree represents a function that takes as input a vector of attribute values and returns a “decision” —a single output value. The input and output values can be discrete or continuous."}  (Russel et al. 2010) \\
In questo lavoro si utlizza il modello decision tree (tramite \href{https://scikit-learn.org/stable/}{scikit-learn} (Pedregosa et al.2011) in Python) al fine di riconoscere sei attività umane (\textit{walking}, \textit{standing}, \textit{sitting}, \textit{laying}, \textit{walking}, \textit{walking upstairs}, \textit{walking downstairs}). Si utilizza un dataset \href{http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones}{UCI}, le modalità con cui sono rilevati i segnali utilizzati per il lavoro sono presenti in Anguita et al. 2012. I dati sono rilevati da 30 soggetti attraverso il giroscopio e l'accellerometro dello smartphone. 


\section{Data pre-processing}
Dopo aver importato il dataset tramite la libreria pandas (McKinney. 2010) si analizza quest'ultimo prima di procedere con il processamento dei dati. Il dataset è gia diviso in train e test, il 70\% è usato per il train set e il rimanente per il test set.
Tramite le funzioni \textit{isnull()} e \textit{duplicated()} di pandas si registra che non presenta valori duplicati o NaN/Null.
Di seguito si mostrano inoltre due grafici:
\begin{itemize}
\item Figura 1.a mostra il "bilanciamento" dei dati; il dataset è piuttosto ben bilanciato, non c'è un'attività rilevata un numero di volte nettamente maggiore/minore rispetto alle altre.
\item Figura 1.b mostra un grafico di dispersione realizzato tramite la funzione della libreria sklearn "sklearn.manifold.TSNE()" che permette di visualizzare in due dimensioni un dataset di alta-dimensione (maggiori dettagli riguardo la funzione in Maate et al. 2008)
\end{itemize}
\subfloat[]{\includegraphics[scale=0.5]{Grafici/data_per_activity.png}}
\hspace*{\fill}
\subfloat[]{\includegraphics[scale=0.35]{Grafici/dispersione.png}}
\caption{(a) bilanciamento dei dati, (b) grafico di dispersione} 
\medskip



\section{Implementazione modello (Decision Tree)}
Il fine di questo lavoro è utilizzare un'implementazione di decision tree per riconoscere attività umane e produrre come risultato una matrice di confusione. 
Si è cercato di ottimizzare il modello sfruttando due tecniche: cross validation e cost complexity pruning.\\

\end{figure}
\begin{figure}
Il modo in cui queste agiscono è presentato nei paragrafi seguenti. L'idea generale è quella di modellare l'albero in modo da evitare overfitting e underfitting. Il modello è underfitting quando non è capace di catturare la relazione tra gli esempi in input e i valori target, in questo caso si hanno delle scarse performance sul training data. Al contrario un modello overfitting ha ottime performance sul training data ma non sul testing data.
Di seguito si riporta una visualizzazione di un sottoalbero di altezza 4 ottenuto con il dataset in questione.
\\
\begin{center}
\includegraphics[scale=0.3]{Grafici/tree2.png} 
\caption{decision tree}
\end{center}


\subsection{Cost complexity pruning}
Minimal cost complexity pruning è un algoritmo che incrementa il numero di nodi tagliati all'aumentare di un parametro che viene nominato alpha. Si basa sulla ricerca ricorsiva del "weakest link" che dunque verrà eliminato. L'algoritmo è descritto nel capitolo 3 di Breiman et al. 1984. \\
Di seguito è riportato un grafico che mostra l'andamento della profondità dell'albero al variare del valore di \textit{ccp\_alpha}.
Come prima cosa si deve capire quali possono essere i valori appropriati per ccp\_alpha. Per farlo si usa la funzione della libreria sklearn \textit{DecisionTreeClassifier.cost\_complexity\_pruning\_path} la quale ritorna un dizionario formato dagli effettivi valori di alfa per ogni sottoalbero e la somma delle impurità delle foglie del sottoalbero per il corrispondente valore di alpha.\\
Conseguentemente addestriamo il decision tree usando tali valori di alfa. Figura 1.a mostra la variazione della profondità al variare di alfa. 
\begin{center}
\subfloat[]{\includegraphics[scale=0.45]{Grafici/depth.png}}
\hspace*{\fill}
\subfloat[]{\includegraphics[scale=0.42]{Grafici/accuratezza.png}}
\caption{accuratezza}
\end{center}
\end{figure}
\begin{figure}

La decrescita è molto rapida per valori piccoli di alpha (compresi fra 0.00 e 0.01) mentre tende ad rallentare dopo questo intervallo.\\
Da Figura 1.b si nota invece che quando ccp\_alpha è settato a 0 si ha overfit, infati il training set ha un'accuratezza del 100\% ma questo non corrisponde al massimo valore del testing set.
Si nota dal grafico che nel punto in cui l'accuratezza per il testing set è masssima rimane comunque molto alta l'accuratezza del training set(sicuramente maggiore di 0.9 non comparendo nell'ingrandimento posto in alto a destra). Il valore di ccp\_alpha per cui si raggiunge la massima accuratezza nel testing set risulta essere 0.000979.

\subsection{Cross Validation}
Una diversa soluzione per evitare l'overfitting è dividere il dataset non più in due set (train set e test set) ma in tre set: \textit{train set, validation set, e test set}. Il dataset è stato diviso per questo studio in maniera diversa, in particolare il test set non è costituito più dal 30\% del dataset ma dal 20\% mentre il rimanente è lasciato a train e validation. Nel validation set si sperimentano alcune varianti del decision tree agendo sui suoi parametri. 
In particolare si è usato la 5-fold cross validation che consiste nella suddivisione del training set in 5 parti di uguale numerosità e, ad ogni passo, la k-esima parte del dataset è il validation set mentre la restante costituisce il training set. 
Per farlo si è usato il modulo di scikit-learn \href{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html}{GridSearchCV} che prende in ingresso una griglia di parametri e come risultato si ottiene la combinazione di questi per i quali è massima l'accuratezza sul validation set. I parametri su cui si è lavorato sono quattro, in parentesi l'intervallo di valori testati per ciascun parametro:
\begin{itemize}
\item \textit{criterion}: funzione per misurare la qualità di uno split. ["gini", "entropy"].
\item \textit{max\_depth}: massima profondità dell'albero. [4 - 17]
\item \textit{min\_samples\_leaf}: minimo numero di "samples" richiesti per fare lo split di un nodo [2 - 14]
\item \textit{min\_samples\_split}: minimo numero di "samples" richiesti per essere una foglia [2 - 14]
\end{itemize}
La migliore combinazione di parametri risulta essere: \textit{criterion = 'entropy', 'max\_depth'= 13, 'min\_samples\_leaf'= 2, 'min\_samples\_split'= 14.}


\section{Risultati }
Figura 4 mostra i risultati in termini di accuratezza per ciascuna tecnica.
La massima accuratezza si ottiene nel caso CV ma si deve considerare il fatto che è calcolata su un test set ridotto rispetto a quello di CCP e NO-Pruning. Infatti come visto in Sez. 3.2 in questo caso si è lavorato con un test set di dimensione 20\% rispetto al dataset.
Di seguito sono riportate matrice di confusione e classification report per CCP(Figra 5.a) e CV(figura 5.b)
\\
\begin{center}
\includegraphics[scale=0.5]{Grafici/comparison_table.png} 

\caption{Risultati}
\end{center}
Matrice di confusione e classification report sono prodotti rispettettivamente con \textit{confusion\_matrix()} e \textit{classification\_report()} di sklearn.metrics.
\end{figure}
\begin{figure}
In entrambi i casi non ci  errori nel riconoscere laying. Ha senso il fatto che siano "confuse" in piccola percentuale le attività di standing e sitting trattandosi di due attività entrambe statiche. Ciò si poteva anche pronosticare dal grafo di dispersione (Figura 1.b) dove si hanno dei dataset corrispondenti al sitting (in blu) nella parte rossa corrispondente a standing e viceversa. Allo stesso modo si può commentare le attività dinamiche ("walking, waking upstairs e walking downstairs"). Di seguito alla matrice di confusione si riporta il classification report con precision, recall, f1-score, e support per ciascuna attività. 
\begin{center}

\includegraphics[scale=0.5]{Grafici/confusion_matrix.png}
\hspace*{\fill}
\includegraphics[scale=0.5]{Grafici/cm2.png}

\subfloat[]{\includegraphics[scale=0.3]{Grafici/cr1.png}}
\hspace*{\fill}
\subfloat[]{\includegraphics[scale=0.3]{Grafici/cr2.png}}
\caption{matrice di confusione e classification report, (a) CCP (b) CV}
\end{center}


\section{References}
\begin{itemize}
\item []D. Anguita, A.Ghio, L.Oneto, X.Parra and J.L.Reyes-Ortiz. Human Activity Recognition on Smartphones
using a Multiclass Hardware-Friendly Support
Vector Machine. 2012
\item []L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wadsworth, Belmont, CA, 1984.
\item []L.v.d. Maaten, G. Hinton. Visualizing data using t-SNE , L.v.d. Maaten, G. Hinton. Journal of Machine Learning Research, Vol 9(Nov), pp. 2579—2605. 2008.
\item []Pedregosa et al. Scikit-learn: Machine Learning in Python, JMLR 12, pp. 2825-2830, 2011.
\item []Stuart Russell and Peter Norvig. Artificial Intelligence: A Modern Ap-
proach. 3rd edition. Pearson, 2010.
\item []Wes McKinney. Data Structured for Statistical Computing in Phyton. pp.51-56. 2010
\end{itemize}
\end{figure}

\end{document}